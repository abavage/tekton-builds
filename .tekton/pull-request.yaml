apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: pull-request
  annotations:
    # The event we are targeting as seen from the webhook payload
    # this can be an array too, i.e: [pull_request, push]
    pipelinesascode.tekton.dev/on-event: "[pull_request]"

    # The branch or tag we are targeting (ie: main, refs/tags/*)
    pipelinesascode.tekton.dev/on-target-branch: "[main]"

    # Fetch the git-clone task from hub, we are able to reference later on it
    # with taskRef and it will automatically be embedded into our pipeline.
    ##pipelinesascode.tekton.dev/task: "git-clone:0.10.0"

    # Use golangci-lint from the hub to test our Golang project
    ##pipelinesascode.tekton.dev/task-1: "buildah:0.8.0"

    # You can add more tasks by increasing the suffix number, you can specify
    # them as array to have multiple of them.
    # browse the tasks you want to include from hub on https://hub.tekton.dev/
    #
    # pipelinesascode.tekton.dev/task-2: "[curl, buildah]"

    # how many runs we want to keep attached to this event
    ##pipelinesascode.tekton.dev/max-keep-runs: "5"
spec:
  params:
    # The variable with brackets are special to Pipelines as Code
    # They will automatically be expanded with the events from Github.
    - name: repo_url
      value: "{{ repo_url }}"
    - name: revision
      value: "{{ revision }}"
    - name: image
      value: "image-registry.openshift-image-registry.svc:5000/image-builds/test:{{ revision }}"
    - name: base_image
      value: "quay.io/abavage/base-image/base-image:latest"
    - name: bucket
      value: "one-openshift-pipeline-image-builds"
  pipelineSpec:
    params:
      - name: repo_url
      - name: revision
      #- name: IMAGE
      #- name: CONTAINERFILE_PATH
    workspaces:
      - name: source
      - name: basic-auth
    
    tasks:
      - name: fetch-repository
        taskRef:
          resolver: cluster
          params:
            - name: kind
              value: task
            - name: name
              value: git-clone-1-20-0
            - name: namespace
              value: openshift-pipelines
        workspaces:
          - name: output
            workspace: source
          - name: basic-auth
            workspace: basic-auth
        params:
          - name: URL
            value: $(params.repo_url)
          - name: REVISION
            value: $(params.revision)
          - name: DELETE_EXISTING
            value: "true"
      
      - name: build-image
        taskRef:
          resolver: cluster
          params:
            - name: kind
              value: task
            - name: name
              value: buildah-1-20-0
            - name: namespace
              value: openshift-pipelines
        workspaces:
          - name: source
            workspace: source
          #- name: basic-auth
          #  workspace: basic-auth
        params:
          - name: IMAGE
            value: "$(params.image)"
          - name: TLS_VERIFY
            value: true
          - name: VERBOSE
            value: false
          - name: DOCKERFILE
            value: ./containerfile
        runAfter:
          - fetch-repository

      - name: cleanup-failed-resources
        taskRef:
          params:
          - name: kind
            value: task
          - name: name
            value: openshift-client
          - name: namespace
            value: openshift-pipelines
          resolver: cluster
        runAfter:
        - build-image
        params:
        - name: SCRIPT
          value: |
            #!/bin/bash

            Clean_up () {
              oc delete deploy build-deploy -n image-builds || true
              oc delete cm index -n image-builds || true
              oc delete svc build-deploy -n image-builds || true
              oc delete route build-deploy -n image-builds || true
            }
            echo "Cleaning up any failed resources"
            Clean_up
        runAfter:
        - build-image


      - name: test-image
        taskRef:
          params:
          - name: kind
            value: task
          - name: name
            value: openshift-client
          - name: namespace
            value: openshift-pipelines
          resolver: cluster
        workspaces:
          - name: manifest_dir
            workspace: source
        params:
        - name: SCRIPT
          value: |
            #!/bin/bash

            Create_resources () {
              oc create deploy build-deploy --image="$(params.image)" --replicas=0 -n image-builds
              oc set resources deployment build-deploy --limits=cpu=200m,memory=256Mi --requests=cpu=100m,memory=125Mi -n image-builds

              oc patch deployment build-deploy --type=merge -p '{"spec": {"template": {"spec": {"containers": [{"name": "build-deploy", "image": "$(params.image)", "livenessProbe": {"tcpSocket": {"port": 8080}, "initialDelaySeconds": 15, "periodSeconds": 10, "timeoutSeconds": 2, "failureThreshold": 3}, "readinessProbe": {"tcpSocket": {"port": 8080}, "initialDelaySeconds": 15, "periodSeconds": 10, "timeoutSeconds": 2, "failureThreshold": 3}}]}}}}' -n image-builds

              oc create cm index --from-file=index.html -n image-builds
              oc set volume deploy/build-deploy --add --configmap-name=index --mount-path=/var/www/html/ --name=index -n image-builds

              oc create svc clusterip build-deploy --tcp=8080:8080 -n image-builds
              oc create route edge build-deploy --service=build-deploy --insecure-policy=Redirect -n image-builds
              oc scale deploy build-deploy --replicas=1 -n image-builds
            }

            Clean_up () {
              oc delete deploy build-deploy -n image-builds
              oc delete cm index -n image-builds
              oc delete svc build-deploy -n image-builds
              oc delete route build-deploy -n image-builds
            }

            echo 'Creating resources to test the new image -- "$(params.image)" '
            Create_resources


            MAX_RETRIES=60
            SLEEP_BETWEEN_RETRIES=1
            ROUTE=$(oc get route build-deploy -o jsonpath='{.spec.host}' | tr -d '[:space:]')

            attempt=1
            while (( attempt <= MAX_RETRIES )); do
              CURL=$(curl -s -o /dev/null -w "%{http_code}" "https://${ROUTE}")

              if [[ "$CURL" == "200" ]]; then
                echo "HTTP 200 received from ${ROUTE}"
                echo ""
                echo "Removing the objects used for testing the image."
                Clean_up
                exit 0
              else
                echo "Attempt $attempt/$MAX_RETRIES failed (HTTP $CURL). Retrying in $SLEEP_BETWEEN_RETRIES sec..."
                (( attempt++ ))
                sleep "$SLEEP_BETWEEN_RETRIES"
              fi
            done

            echo "Failed to receive HTTP 200 from ${ROUTE} after $MAX_RETRIES attempts."
            exit 1
        runAfter:
        - cleanup-failed-resources

      - name: copy-git-sha-to-s3
        #params:
        #  - name: namespace
        #    value: image-builds
        taskSpec:
          #params:
          #  - name: namespace
          #    type: string
          #    description: "Namespace where the imagestream will reside"
          steps:
            - name: copy-git-sha-to-s3
              image: "$(params.base_image)"
              script: |
                #!/bin/bash

                RELEASE=$(params.revision)
                BUCKET=$(params.bucket)
    
                echo $RELEASE
                
                ls -al /workspace/source

        workspaces:
          - name: source
            workspace: source
        runAfter:
        - test-image

  workspaces:
    - name: source
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
    # This workspace will inject secret to help the git-clone task to be able to
    # checkout the private repositories
    - name: basic-auth
      secret:
        secretName: "{{ git_auth_secret }}"
